import re
from dataclasses import dataclass

from trae_agent.agent.agent_basics import AgentStep
from trae_agent.utils.config import LakeviewConfig
from trae_agent.utils.llm_clients.llm_basics import LLMMessage
from trae_agent.utils.llm_clients.llm_client import LLMClient

StepType = tuple[
    str,  # content for human (will write into result file)
    str
    | None,  # content for llm, or None if no need to analyze (i.e., minor step), watch out length limit
]


EXTRACTOR_PROMPT = """
æ ¹æ®å‰é¢çš„æ‘˜å½•ï¼Œä½ çš„ä»»åŠ¡æ˜¯ç¡®å®š"ä»£ç†åœ¨<this_step>ä¸­æ­£åœ¨æ‰§è¡Œä»€ä¹ˆä»»åŠ¡"ã€‚
è¯·ç”¨ä¸¤ä¸ªå±‚æ¬¡è¾“å‡ºä½ çš„ç­”æ¡ˆï¼š<task>...</task><details>...</details>ã€‚
åœ¨<task>æ ‡ç­¾ä¸­ï¼Œç­”æ¡ˆåº”è¯¥ç®€æ´è€Œæ¦‚æ‹¬ã€‚å®ƒåº”è¯¥çœç•¥ä»»ä½•ç‰¹å®šäºbugçš„ç»†èŠ‚ï¼Œæœ€å¤šåŒ…å«10ä¸ªè¯ã€‚
åœ¨<details>æ ‡ç­¾ä¸­ï¼Œç­”æ¡ˆåº”è¯¥é€šè¿‡æ·»åŠ ç‰¹å®šäºbugçš„ç»†èŠ‚æ¥è¡¥å……<task>æ ‡ç­¾ã€‚å®ƒåº”è¯¥æ˜¯ä¿¡æ¯ä¸°å¯Œçš„ï¼Œæœ€å¤šåŒ…å«30ä¸ªè¯ã€‚

ç¤ºä¾‹ï¼š

<task>ä»£ç†æ­£åœ¨ç¼–å†™å¤ç°æµ‹è¯•è„šæœ¬ã€‚</task><details>ä»£ç†æ­£åœ¨ç¼–å†™"test_bug.py"æ¥å¤ç°XXX-Projectçš„create_fooæ–¹æ³•æœªæ­£ç¡®æ¯”è¾ƒå¤§å°çš„bugã€‚</details>
<task>ä»£ç†æ­£åœ¨æ£€æŸ¥æºä»£ç ã€‚</task><details>ä»£ç†æ­£åœ¨ä»£ç ä»“åº“ä¸­æœç´¢"function_name"ï¼Œè¿™ä¸å †æ ˆè·Ÿè¸ªä¸­çš„"foo.py:function_name"è¡Œç›¸å…³ã€‚</details>
<task>ä»£ç†æ­£åœ¨ä¿®å¤å¤ç°æµ‹è¯•è„šæœ¬ã€‚</task><details>ä»£ç†æ­£åœ¨ä¿®å¤"test_bug.py"ï¼Œè¯¥è„šæœ¬å¿˜è®°å¯¼å…¥å‡½æ•°"foo"ï¼Œå¯¼è‡´NameErrorã€‚</details>

ç°åœ¨ï¼Œå›ç­”é—®é¢˜"ä»£ç†åœ¨<this_step>ä¸­æ­£åœ¨æ‰§è¡Œä»€ä¹ˆä»»åŠ¡"ã€‚
å†æ¬¡å¼ºè°ƒï¼Œåªæä¾›ç­”æ¡ˆï¼Œä¸è¦å…¶ä»–è¯„è®ºã€‚æ ¼å¼åº”è¯¥æ˜¯"<task>...</task><details>...</details>"ã€‚
"""

TAGGER_PROMPT = """
æ ¹æ®è½¨è¿¹ï¼Œä½ çš„ä»»åŠ¡æ˜¯ç¡®å®š"ä»£ç†åœ¨å½“å‰æ­¥éª¤ä¸­æ­£åœ¨æ‰§è¡Œä»€ä¹ˆä»»åŠ¡"ã€‚
é€šè¿‡ä»ä¸‹é¢çš„åˆ—è¡¨ä¸­é€‰æ‹©é€‚ç”¨äºå½“å‰æ­¥éª¤çš„æ ‡ç­¾æ¥è¾“å‡ºä½ çš„ç­”æ¡ˆã€‚
å¦‚æœå®ƒåœ¨ä¸€ä¸ªæ­¥éª¤ä¸­æ‰§è¡Œå¤šä¸ªä»»åŠ¡ï¼Œè¯·é€‰æ‹©æ‰€æœ‰é€‚ç”¨çš„æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”ã€‚

<tags>
WRITE_TEST: å®ƒç¼–å†™æµ‹è¯•è„šæœ¬æ¥å¤ç°bugï¼Œæˆ–ä¿®æ”¹æ— æ³•å·¥ä½œçš„æµ‹è¯•è„šæœ¬ä»¥ä¿®å¤æµ‹è¯•ä¸­å‘ç°çš„é—®é¢˜ã€‚
VERIFY_TEST: å®ƒè¿è¡Œå¤ç°æµ‹è¯•è„šæœ¬æ¥éªŒè¯æµ‹è¯•ç¯å¢ƒæ˜¯å¦æ­£å¸¸å·¥ä½œã€‚
EXAMINE_CODE: å®ƒæŸ¥çœ‹ã€æœç´¢æˆ–æ¢ç´¢ä»£ç ä»“åº“ä»¥äº†è§£bugçš„åŸå› ã€‚
WRITE_FIX: å®ƒä¿®æ”¹æºä»£ç ä»¥ä¿®å¤å·²è¯†åˆ«çš„bugã€‚
VERIFY_FIX: å®ƒè¿è¡Œå¤ç°æµ‹è¯•æˆ–ç°æœ‰æµ‹è¯•æ¥éªŒè¯ä¿®å¤ç¡®å®è§£å†³äº†bugã€‚
REPORT: å®ƒå‘ç”¨æˆ·æŠ¥å‘Šå·¥ä½œå·²å®Œæˆæˆ–å–å¾—äº†ä¸€äº›è¿›å±•ã€‚
THINK: å®ƒé€šè¿‡æ€è€ƒåˆ†æbugï¼Œä½†ç›®å‰ä¸æ‰§è¡Œå…·ä½“è¡ŒåŠ¨ã€‚
OUTLIER: æ­¤æ­¥éª¤çš„ä¸»è¦éƒ¨åˆ†ä¸ç¬¦åˆä¸Šè¿°ä»»ä½•æ ‡ç­¾ï¼Œä¾‹å¦‚è¿è¡Œshellå‘½ä»¤å®‰è£…ä¾èµ–é¡¹ã€‚
</tags>

<examples>
å¦‚æœä»£ç†æ­£åœ¨æ‰“å¼€æ–‡ä»¶è¿›è¡Œæ£€æŸ¥ï¼Œè¾“å‡º<tags>EXAMINE_CODE</tags>ã€‚
å¦‚æœä»£ç†æ­£åœ¨ä¿®å¤å¤ç°æµ‹è¯•è„šæœ¬ä¸­çš„å·²çŸ¥é—®é¢˜ç„¶åå†æ¬¡è¿è¡Œå®ƒï¼Œè¾“å‡º<tags>WRITE_TEST,VERIFY_TEST</tags>ã€‚
å¦‚æœä»£ç†ä»…ä»…åœ¨æ€è€ƒbugçš„æ ¹æœ¬åŸå› è€Œæ²¡æœ‰å…¶ä»–è¡ŒåŠ¨ï¼Œè¾“å‡º<tags>THINK</tags>ã€‚
</examples>

åªè¾“å‡ºæ ‡ç­¾ï¼Œä¸è¦å…¶ä»–è¯„è®ºã€‚æ ¼å¼åº”è¯¥æ˜¯<tags>...</tags>
"""

KNOWN_TAGS = {
    "WRITE_TEST": "â˜‘ï¸",
    "VERIFY_TEST": "âœ…",
    "EXAMINE_CODE": "ğŸ‘ï¸",
    "WRITE_FIX": "ğŸ“",
    "VERIFY_FIX": "ğŸ”¥",
    "REPORT": "ğŸ“£",
    "THINK": "ğŸ§ ",
    "OUTLIER": "â‰ï¸",
}

tags_re = re.compile(r"<tags>([A-Z_,\s]+)</tags>")


@dataclass
class LakeViewStep:
    desc_task: str
    desc_details: str
    tags_emoji: str


class LakeView:
    def __init__(self, lake_view_config: LakeviewConfig | None):
        if lake_view_config is None:
            return

        self.model_config = lake_view_config.model
        self.lakeview_llm_client: LLMClient = LLMClient(self.model_config)

        self.steps: list[str] = []

    def get_label(self, tags: None | list[str], emoji: bool = True) -> str:
        if not tags:
            return ""

        return " Â· ".join([KNOWN_TAGS[tag] + tag if emoji else tag for tag in tags])

    async def extract_task_in_step(self, prev_step: str, this_step: str) -> tuple[str, str]:
        llm_messages = [
            LLMMessage(
                role="user",
                content=f"The following is an excerpt of the steps trying to solve a software bug by an AI agent: <previous_step>{prev_step}</previous_step><this_step>{this_step}</this_step>",
            ),
            LLMMessage(role="assistant", content="I understand."),
            LLMMessage(role="user", content=EXTRACTOR_PROMPT),
            LLMMessage(
                role="assistant",
                content="Sure. Here is the task the agent is performing: <task>The agent",
            ),
        ]

        self.model_config.temperature = 0.1
        llm_response = self.lakeview_llm_client.chat(
            model_config=self.model_config,
            messages=llm_messages,
            reuse_history=False,
        )

        content = llm_response.content.strip()

        retry = 0
        while retry < 10 and (
            "</task>" not in content or "<details>" not in content or "</details>" not in content
        ):
            retry += 1
            llm_response = self.lakeview_llm_client.chat(
                model_config=self.model_config,
                messages=llm_messages,
                reuse_history=False,
            )
            content = llm_response.content.strip()

        if "</task>" not in content or "<details>" not in content or "</details>" not in content:
            return "", ""

        desc_task, _, desc_details = content.rpartition("</task>")
        desc_details = desc_details.replace("<details>", "[italic]").replace(
            "</details>", "[/italic]"
        )
        return desc_task, desc_details

    async def extract_tag_in_step(self, step: str) -> list[str]:
        steps_fmt = "\n\n".join(
            f'<step id="{ind + 1}">\n{s.strip()}\n</step>' for ind, s in enumerate(self.steps)
        )

        if len(steps_fmt) > 300_000:
            # step_fmt is too long, skip tagging
            return []

        llm_messages = [
            LLMMessage(
                role="user",
                content=f"Below is the trajectory of an AI agent solving a software bug until the current step. Each step is marked within a <step> tag.\n\n{steps_fmt}\n\n<current_step>{step}</current_step>",
            ),
            LLMMessage(role="assistant", content="I understand."),
            LLMMessage(role="user", content=TAGGER_PROMPT),
            LLMMessage(role="assistant", content="Sure. The tags are: <tags>"),
        ]
        self.model_config.temperature = 0.1

        retry = 0
        while retry < 10:
            llm_response = self.lakeview_llm_client.chat(
                model_config=self.model_config,
                messages=llm_messages,
                reuse_history=False,
            )

            content = "<tags>" + llm_response.content.lstrip()

            matched_tags: list[str] = tags_re.findall(content)
            if not matched_tags:
                break
            tags: list[str] = [tag.strip() for tag in matched_tags[0].split(",")]
            if all(tag in KNOWN_TAGS for tag in tags):
                return tags

            retry += 1

        return []

    def _agent_step_str(self, agent_step: AgentStep) -> str | None:
        if agent_step.llm_response is None:
            return None

        content = agent_step.llm_response.content.strip()

        tool_calls_content = ""
        if agent_step.llm_response.tool_calls is not None:
            tool_calls_content = "\n".join(
                f"[`{tool_call.name}`] `{tool_call.arguments}`"
                for tool_call in agent_step.llm_response.tool_calls
            )
            tool_calls_content = tool_calls_content.strip()
            content = f"{content}\n\nTool calls:\n{tool_calls_content}"

        return content

    async def create_lakeview_step(self, agent_step: AgentStep) -> LakeViewStep | None:
        previous_step_str = "(none)"
        if len(self.steps) > 1:
            previous_step_str = self.steps[-1]

        this_step_str = self._agent_step_str(agent_step)

        if this_step_str:
            desc_task, desc_details = await self.extract_task_in_step(
                previous_step_str, this_step_str
            )
            tags = await self.extract_tag_in_step(this_step_str)
            tags_emoji = self.get_label(tags)
            return LakeViewStep(desc_task, desc_details, tags_emoji)

        return None
